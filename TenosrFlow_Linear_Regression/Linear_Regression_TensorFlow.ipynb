{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1=tf.constant(3,tf.float32)\n",
    "node2=tf.constant(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(node1)\n",
    "print(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(node1)\n",
    "sess.run(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Additon\n",
    "node3=tf.add(node1,node2)\n",
    "#not possible as both aere of diff data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1=tf.constant(3)\n",
    "node2=tf.constant(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node3=tf.add(node1,node2) #node1+node2 will also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##A graph can be parameterized to accept external inputs, known as placeholders.\n",
    "#A placeholder is a promise to provide a value later.\n",
    "a=tf.placeholder(tf.int32)\n",
    "b=tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add=a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(add,{a:3,b:5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(add*3,{a:3,b:5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value:\n",
    "W = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x=tf.placeholder(tf.float32)\n",
    "linear_model=W*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#variables must be intialized in order to use it\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)#this is for intilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(sess.run(linear_model, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv',sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.502345</td>\n",
       "      <td>31.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.426804</td>\n",
       "      <td>68.777596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61.530358</td>\n",
       "      <td>62.562382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.475640</td>\n",
       "      <td>71.546632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.813208</td>\n",
       "      <td>87.230925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.142188</td>\n",
       "      <td>78.211518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52.211797</td>\n",
       "      <td>79.641973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39.299567</td>\n",
       "      <td>59.171489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.105042</td>\n",
       "      <td>75.331242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52.550014</td>\n",
       "      <td>71.300880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1\n",
       "0  32.502345  31.707006\n",
       "1  53.426804  68.777596\n",
       "2  61.530358  62.562382\n",
       "3  47.475640  71.546632\n",
       "4  59.813208  87.230925\n",
       "5  55.142188  78.211518\n",
       "6  52.211797  79.641973\n",
       "7  39.299567  59.171489\n",
       "8  48.105042  75.331242\n",
       "9  52.550014  71.300880"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points=genfromtxt('data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.50234527,  53.42680403,  61.53035803,  47.47563963,\n",
       "        59.81320787,  55.14218841,  52.21179669,  39.29956669,\n",
       "        48.10504169,  52.55001444,  45.41973014,  54.35163488,\n",
       "        44.1640495 ,  58.16847072,  56.72720806,  48.95588857,\n",
       "        44.68719623,  60.29732685,  45.61864377,  38.81681754,\n",
       "        66.18981661,  65.41605175,  47.48120861,  41.57564262,\n",
       "        51.84518691,  59.37082201,  57.31000344,  63.61556125,\n",
       "        46.73761941,  50.55676015,  52.22399609,  35.56783005,\n",
       "        42.43647694,  58.16454011,  57.50444762,  45.44053073,\n",
       "        61.89622268,  33.09383174,  36.43600951,  37.67565486,\n",
       "        44.55560838,  43.31828263,  50.07314563,  43.87061265,\n",
       "        62.99748075,  32.66904376,  40.16689901,  53.57507753,\n",
       "        33.86421497,  64.70713867,  38.11982403,  44.50253806,\n",
       "        40.59953838,  41.72067636,  51.08863468,  55.0780959 ,\n",
       "        41.37772653,  62.49469743,  49.20388754,  41.10268519,\n",
       "        41.18201611,  50.18638949,  52.37844622,  50.13548549,\n",
       "        33.64470601,  39.55790122,  56.13038882,  57.36205213,\n",
       "        60.26921439,  35.67809389,  31.588117  ,  53.66093226,\n",
       "        46.68222865,  43.10782022,  70.34607562,  44.49285588,\n",
       "        57.5045333 ,  36.93007661,  55.80573336,  38.95476907,\n",
       "        56.9012147 ,  56.86890066,  34.3331247 ,  59.04974121,\n",
       "        57.78822399,  54.28232871,  51.0887199 ,  50.28283635,\n",
       "        44.21174175,  38.00548801,  32.94047994,  53.69163957,\n",
       "        68.76573427,  46.2309665 ,  68.31936082,  50.03017434,\n",
       "        49.23976534,  50.03957594,  48.14985889,  25.12848465])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(points)\n",
    "points[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divided our data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=points[0:80,0]\n",
    "y_train=points[0:80,1]\n",
    "x_eval=points[80:100,0]\n",
    "y_eval=points[80:100,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32.50234527,  53.42680403,  61.53035803,  47.47563963,\n",
       "        59.81320787,  55.14218841,  52.21179669,  39.29956669,\n",
       "        48.10504169,  52.55001444,  45.41973014,  54.35163488,\n",
       "        44.1640495 ,  58.16847072,  56.72720806,  48.95588857,\n",
       "        44.68719623,  60.29732685,  45.61864377,  38.81681754,\n",
       "        66.18981661,  65.41605175,  47.48120861,  41.57564262,\n",
       "        51.84518691,  59.37082201,  57.31000344,  63.61556125,\n",
       "        46.73761941,  50.55676015,  52.22399609,  35.56783005,\n",
       "        42.43647694,  58.16454011,  57.50444762,  45.44053073,\n",
       "        61.89622268,  33.09383174,  36.43600951,  37.67565486,\n",
       "        44.55560838,  43.31828263,  50.07314563,  43.87061265,\n",
       "        62.99748075,  32.66904376,  40.16689901,  53.57507753,\n",
       "        33.86421497,  64.70713867,  38.11982403,  44.50253806,\n",
       "        40.59953838,  41.72067636,  51.08863468,  55.0780959 ,\n",
       "        41.37772653,  62.49469743,  49.20388754,  41.10268519,\n",
       "        41.18201611,  50.18638949,  52.37844622,  50.13548549,\n",
       "        33.64470601,  39.55790122,  56.13038882,  57.36205213,\n",
       "        60.26921439,  35.67809389,  31.588117  ,  53.66093226,\n",
       "        46.68222865,  43.10782022,  70.34607562,  44.49285588,\n",
       "        57.5045333 ,  36.93007661,  55.80573336,  38.95476907])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x117b82668>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': None}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/_3/ck8mb1qn35dg_y8z655dyx358dk92j/T/tmp29ju7prb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#simlar to sklearn importing the required Algorithm to use\n",
    "#Give the input of your feature columns\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Give your Data\n",
    "##This is also similar to sklearn\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x_train}, y_train,\n",
    "                                              batch_size=4,\n",
    "                                              num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating the test \n",
    "eval_input_fn = tf.contrib.learn.io.numpy_input_fn(\n",
    "    {\"x\":x_eval}, y_eval, batch_size=4, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4 :No fo Training Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/jmandivara/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/_3/ck8mb1qn35dg_y8z655dyx358dk92j/T/tmp29ju7prb/model.ckpt.\n",
      "INFO:tensorflow:loss = 4725.19, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1439.37\n",
      "INFO:tensorflow:loss = 98.1073, step = 101 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1422.59\n",
      "INFO:tensorflow:loss = 72.7025, step = 201 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1461.97\n",
      "INFO:tensorflow:loss = 147.472, step = 301 (0.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 1418.36\n",
      "INFO:tensorflow:loss = 56.2735, step = 401 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1429.58\n",
      "INFO:tensorflow:loss = 98.7253, step = 501 (0.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 1412.55\n",
      "INFO:tensorflow:loss = 77.7186, step = 601 (0.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 1359.06\n",
      "INFO:tensorflow:loss = 129.524, step = 701 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 1441.36\n",
      "INFO:tensorflow:loss = 35.4011, step = 801 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1222.58\n",
      "INFO:tensorflow:loss = 163.462, step = 901 (0.082 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/_3/ck8mb1qn35dg_y8z655dyx358dk92j/T/tmp29ju7prb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 80.2678.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x117acceb8>, 'feature_columns': [_RealValuedColumn(column_name='x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': None, 'gradient_clip_norm': None, 'joint_weights': False})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step4 :No fo Training Steps\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Calculating the Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/jmandivara/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-25-13:38:10\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_3/ck8mb1qn35dg_y8z655dyx358dk92j/T/tmp29ju7prb/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-25-13:38:19\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 115.093\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /Users/jmandivara/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-25-13:38:19\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_3/ck8mb1qn35dg_y8z655dyx358dk92j/T/tmp29ju7prb/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-25-13:38:21\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 99.2819\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "train loss: {'loss': 115.09311, 'global_step': 1000}\n",
      "eval loss: {'loss': 99.281891, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate how well our model did.\n",
    "train_loss = estimator.evaluate(input_fn=input_fn)\n",
    "eval_loss = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train loss: %r\"% train_loss)\n",
    "print(\"eval loss: %r\"% eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
